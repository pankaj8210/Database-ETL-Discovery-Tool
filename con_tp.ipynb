{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating connection to sql database using python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriving Data from The SQL Server Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Qeries to fetch all data from the database and save it to a CSV file in seperate folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original mutliple query <- accessing data <- and saving into csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessed Data Source converted to CSV format with the each data with table name and saved into separate database folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# SQL Server connection parameters\n",
    "server = 'OPTIMUS_PRIME'\n",
    "database = 'AdventureWorks2022'\n",
    "trusted_connection = 'yes'   # Use Windows authentication\n",
    "\n",
    "# Establish a connection to the SQL Server\n",
    "conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection={trusted_connection};'\n",
    "try:\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the database: {e}\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Create a cursor to execute SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch the list of tables in the database along with their schema\n",
    "tables_query = \"\"\"\n",
    "    SELECT table_schema, table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_type = 'BASE TABLE';\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(tables_query)\n",
    "    table_rows = cursor.fetchall()\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching tables: {e}\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    raise SystemExit\n",
    "\n",
    "# Create a new folder to save CSV files\n",
    "output_folder = 'output_sql'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through the list of tables, convert each to a data frame, and save to CSV\n",
    "for row in table_rows:\n",
    "    schema, table = row.table_schema, row.table_name\n",
    "    full_table_name = f\"{schema}.{table}\" if schema else table  # Include schema if it exists\n",
    "\n",
    "    # Fetch column information for the table\n",
    "    columns_query = f\"SELECT COLUMN_NAME, DATA_TYPE FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table}'\"\n",
    "    cursor.execute(columns_query)\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    # Filter out columns with unsupported types\n",
    "    supported_types = ['int', 'nvarchar', 'varchar', 'datetime', 'float', 'decimal']\n",
    "    selected_columns = [col.COLUMN_NAME for col in columns_info if any(col.DATA_TYPE.lower().startswith(supported) for supported in supported_types)]\n",
    "\n",
    "    # Construct the SELECT statement with explicit casting for each selected column\n",
    "    select_columns = ', '.join([f\"CAST([{col}] AS NVARCHAR(MAX)) AS {col}\" if col.lower() != 'group' else f\"CAST([{col}] AS NVARCHAR(MAX)) AS [Group]\" for col in selected_columns])\n",
    "    query = f\"SELECT {select_columns} FROM {full_table_name};\"\n",
    "\n",
    "    try:\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch the data with proper decoding\n",
    "        data = [tuple(cell.decode('utf-8') if isinstance(cell, bytes) else cell for cell in row) for row in cursor.fetchall()]\n",
    "\n",
    "        # Create DataFrame from the fetched data\n",
    "        df = pd.DataFrame(data, columns=selected_columns)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query for table '{full_table_name}': {e}\")\n",
    "        continue\n",
    "\n",
    "    # Save the data frame to a CSV file\n",
    "    csv_filename = os.path.join(output_folder, f\"{table}.csv\")\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import logging\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "\n",
    "# Create a folder for logs\n",
    "log_folder = 'logs_withslack-sql'\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "# Configure the logger to save the log file in the 'logs' folder\n",
    "log_file_path = os.path.join(log_folder, 'fdf_sql.log')\n",
    "logging.basicConfig(filename=log_file_path, level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# SQL Server connection parameters\n",
    "server = 'OPTIMUS_PRIME'\n",
    "database = 'AdventureWorks2022'\n",
    "trusted_connection = 'yes'   # Use Windows authentication\n",
    "\n",
    "# Establish a connection to the SQL Server\n",
    "conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection={trusted_connection};'\n",
    "try:\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    logging.info(\"Connected to the SQL Server successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error connecting to the database: {e}\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Create a cursor to execute SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch the list of tables in the database along with their schema\n",
    "tables_query = \"\"\"\n",
    "    SELECT table_schema, table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_type = 'BASE TABLE';\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(tables_query)\n",
    "    table_rows = cursor.fetchall()\n",
    "    logging.info(\"Fetched the list of tables in the database successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error fetching tables: {e}\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    raise SystemExit\n",
    "\n",
    "# Create a new folder to save CSV files\n",
    "output_folder = 'output_sql_withslk'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize Slack notification message\n",
    "slack_message = \"\"\n",
    "\n",
    "# Loop through the list of tables, convert each to a data frame, and save to CSV\n",
    "for row in table_rows:\n",
    "    schema, table = row.table_schema, row.table_name\n",
    "    full_table_name = f\"{schema}.{table}\" if schema else table  # Include schema if it exists\n",
    "\n",
    "    # Fetch column information for the table\n",
    "    columns_query = f\"SELECT COLUMN_NAME, DATA_TYPE FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table}'\"\n",
    "    cursor.execute(columns_query)\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    # Filter out columns with unsupported types\n",
    "    supported_types = ['int', 'nvarchar', 'varchar', 'datetime', 'float', 'decimal']\n",
    "    selected_columns = [col.COLUMN_NAME for col in columns_info if any(col.DATA_TYPE.lower().startswith(supported) for supported in supported_types)]\n",
    "\n",
    "    # Construct the SELECT statement with explicit casting for each selected column\n",
    "    select_columns = ', '.join([f\"CAST([{col}] AS NVARCHAR(MAX)) AS {col}\" if col.lower() != 'group' else f\"CAST([{col}] AS NVARCHAR(MAX)) AS [Group]\" for col in selected_columns])\n",
    "    query = f\"SELECT {select_columns} FROM {full_table_name};\"\n",
    "\n",
    "    try:\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch the data with proper decoding\n",
    "        data = [tuple(cell.decode('utf-8') if isinstance(cell, bytes) else cell for cell in row) for row in cursor.fetchall()]\n",
    "\n",
    "        # Create DataFrame from the fetched data\n",
    "        df = pd.DataFrame(data, columns=selected_columns)\n",
    "\n",
    "        # Save the data frame to a CSV file\n",
    "        csv_filename = os.path.join(output_folder, f\"{table}.csv\")\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        logging.info(f\"Table '{full_table_name}' successfully processed and saved to '{csv_filename}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error executing query for table '{full_table_name}': {e}\")\n",
    "        slack_message += f\"Error executing query for table '{full_table_name}': {e}\\n\"\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# Log successful completion\n",
    "logging.info(\"Fetching Data From Database And Save into CSV is completed successfully.\")\n",
    "\n",
    "# Initialize Slack API client\n",
    "SLACK_BOT_TOKEN =\"Your Slack Bot Token\"\n",
    "SLACK_CHANNEL_ID = \"Your Slack channel ID\"\n",
    "client = WebClient(token=SLACK_BOT_TOKEN)\n",
    "\n",
    "# Send Slack notification\n",
    "try:\n",
    "    if slack_message:\n",
    "        # If there are errors, send error message\n",
    "        message = f\"Fetchig Data job failed. Here's the summary of the errors:\\n{slack_message}\\n****Please check the logs for more details****\"\n",
    "    else:\n",
    "        # If successful, send success message\n",
    "        message = \"Fetchig Data job completed successfully\"\n",
    "\n",
    "    response = client.chat_postMessage(\n",
    "        channel=SLACK_CHANNEL_ID,\n",
    "        text=message\n",
    "    )\n",
    "    logging.info(\"Slack notification sent successfully.\")\n",
    "except SlackApiError as e:\n",
    "    logging.error(f\"Slack Notification Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Connection to Oracle Database using python and accessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access data from database and return results    handling exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the data from oracle database with pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the data from oracle database with pandas dataframe and saving into json format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing Multiple  data  used multiple query  into oracle database with pandas dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing Multiple data used multiple query into oracle database with pandas dataframe saving into csv file with table names as columns and in seperate folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing data from oracle database converting into dataframe then query database afterwards converting dataframe to csv file and saving to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Database connection details\n",
    "oracle_host = 'localhost'\n",
    "oracle_port = '1521'\n",
    "oracle_service_name = 'xepdb1'\n",
    "username = 'system'\n",
    "password = '12345'\n",
    "\n",
    "\n",
    "target_schema = 'ADVWORKS'\n",
    "\n",
    "\n",
    "# Establishing a connection to the Oracle database\n",
    "connection = cx_Oracle.connect(user=username,\n",
    "                               password=password,\n",
    "                               dsn=f\"{oracle_host}:{oracle_port}/{oracle_service_name}\")\n",
    "\n",
    "# Create a cursor to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Get the list of tables in the database\n",
    "cursor.execute(f\"SELECT table_name FROM all_tables WHERE owner = '{target_schema.upper()}'\")\n",
    "tables = [table[0] for table in cursor.fetchall()]\n",
    "print(\"Tables:\", tables)\n",
    "\n",
    "\n",
    "\n",
    "# Create a folder to save CSV files\n",
    "output_folder = 'output_data-or'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each table, convert to DataFrame, and save as CSV\n",
    "for table_name in tables:\n",
    "    query = f\"SELECT * FROM {target_schema}.{table_name}\"\n",
    "    df = pd.read_sql(query, connection)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_filename = os.path.join(output_folder, f\"{table_name.replace('.', '_')}.csv\")\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "\n",
    "# Create a folder for logs\n",
    "log_folder = 'logs_withslk-oracle'\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "# Configure the logger to save the log file in the 'logs_oracle' folder\n",
    "log_file_path = os.path.join(log_folder, 'fdf_oracle.log')\n",
    "logging.basicConfig(filename=log_file_path, level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# Database connection details\n",
    "oracle_host = 'localhost'\n",
    "oracle_port = '1521'\n",
    "oracle_service_name = 'xepdb1'\n",
    "username = 'system'\n",
    "password = '12345'\n",
    "\n",
    "target_schema = 'ADVWORKS'\n",
    "\n",
    "# Initialize Slack notification message\n",
    "slack_message = \"\"\n",
    "\n",
    "# Establishing a connection to the Oracle database\n",
    "try:\n",
    "    connection = cx_Oracle.connect(user=username,\n",
    "                                   password=password,\n",
    "                                   dsn=f\"{oracle_host}:{oracle_port}/{oracle_service_name}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error connecting to the Oracle database: {e}\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Create a cursor to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Get the list of tables in the database\n",
    "try:\n",
    "    cursor.execute(f\"SELECT table_name FROM all_tables WHERE owner = '{target_schema.upper()}'\")\n",
    "    tables = [table[0] for table in cursor.fetchall()]\n",
    "    logging.info(\"Tables: %s\", tables)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error fetching tables: {e}\")\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    raise SystemExit\n",
    "\n",
    "# Create a folder to save CSV files\n",
    "output_folder = 'output_or_withslk'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each table, convert to DataFrame, and save as CSV\n",
    "for table_name in tables:\n",
    "    query = f\"SELECT * FROM {target_schema}.{table_name}\"\n",
    "    try:\n",
    "        df = pd.read_sql(query, connection)\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        csv_filename = os.path.join(output_folder, f\"{table_name.replace('.', '_')}.csv\")\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        logging.info(\"Table '%s' data saved to CSV successfully.\", table_name)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing table '{table_name}': {e}\")\n",
    "        slack_message += f\"Error processing table '{table_name}': {e}\\n\"\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "# Log successful completion\n",
    "logging.info(\"Oracle Oracle Data Fetching and Saving into CSV  code completed successfully.\")\n",
    "\n",
    "# Initialize Slack API client\n",
    "SLACK_BOT_TOKEN =\"xoxb-6480955639828-6501691359936-LXNhmFOgwC2PRdfpwI6UU0kv\"\n",
    "SLACK_CHANNEL_ID = \"C06DVRG0962\"\n",
    "client = WebClient(token=SLACK_BOT_TOKEN)\n",
    "\n",
    "# Send Slack notification\n",
    "try:\n",
    "    if slack_message:\n",
    "        # If there are errors, send error message\n",
    "        message = f\"Oracle Data Fetching job failed. Here's the summary of the errors:\\n{slack_message}\\n****Please check the logs for more details****\"\n",
    "    else:\n",
    "        # If successful, send success message\n",
    "        message = \"Oracle Data Fetching and Saving into CSV job completed successfully\"\n",
    "\n",
    "    response = client.chat_postMessage(\n",
    "        channel=SLACK_CHANNEL_ID,\n",
    "        text=message\n",
    "    )\n",
    "    logging.info(\"Slack notification sent successfully.\")\n",
    "except SlackApiError as e:\n",
    "    logging.error(f\"Slack Notification Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import cx_Oracle\n",
    "import os\n",
    "\n",
    "import tiktoken\n",
    "import constantsp\n",
    "from langchain.chains import load_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from sqlalchemy import create_engine\n",
    "os.environ[\"OPENAI_API_KEY\"] = constantsp.APIKEY\n",
    "import openai\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import glob\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.agent_types import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlite_db(csv_files, db_name):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        table_name = csv_file.split('.')[0]\n",
    "\n",
    "        df.to_sql(table_name, conn, index=False, if_exists='replace')\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "csv_files = glob.glob('output_data-or/*.csv')\n",
    "db_name = 'sample-or.db'\n",
    "\n",
    "create_sqlite_db(csv_files, db_name)\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///./sample-or.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine(url, echo=True)\n",
    "# Instantiate OpenAI\n",
    "\n",
    "\n",
    "# Instantiate SQLDatabase and SQLDatabaseChain\n",
    "# db = SQLDatabase(engine)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"show the column names present in the DIMACCOUNT table in sample-or database file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import cx_Oracle\n",
    "import os\n",
    "import tiktoken\n",
    "import constantsp\n",
    "from langchain.chains import load_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from sqlalchemy import create_engine\n",
    "os.environ[\"OPENAI_API_KEY\"] = constantsp.APIKEY\n",
    "import openai\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import glob\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.agent_types import AgentType\n",
    "import logging\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "\n",
    "\n",
    "# Create a folder for logs\n",
    "log_folder = 'etl_logs-or'\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "# Configure the logger to save the log file in the 'logs_oracle' folder\n",
    "log_file_path = os.path.join(log_folder, 'etl_or.log')\n",
    "logging.basicConfig(filename=log_file_path, level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# Initialize Slack notification message\n",
    "slack_message = \"\"\n",
    "def create_sqlite_db(csv_files, db_name):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_name)\n",
    "\n",
    "        for csv_file in csv_files:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            table_name = csv_file.split('.')[0]\n",
    "\n",
    "            df.to_sql(table_name, conn, index=False, if_exists='replace')\n",
    "            logging.info(f\"Table '{table_name}' created successfully from CSV file '{csv_file}'\")\n",
    "\n",
    "        # Close the database connection\n",
    "        conn.close()\n",
    "        logging.info(\"SQLite database connection closed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in creating SQLite database: {str(e)}\")\n",
    "        slack_message += f\"Error in creating SQLite database: {str(e)}\\n\"\n",
    "\n",
    "csv_files = glob.glob('output_or_withslk/*.csv')\n",
    "db_name = 'or.db'\n",
    "\n",
    "create_sqlite_db(csv_files, db_name)\n",
    "\n",
    "try:\n",
    "    db = SQLDatabase.from_uri(\"sqlite:///./or.db\")\n",
    "    logging.info(\"SQLDatabase created successfully from SQLite database.\")\n",
    "\n",
    "    # Instantiate OpenAI\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "    logging.info(\"ChatOpenAI instance created.\")\n",
    "\n",
    "    toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "    logging.info(\"SQLDatabaseToolkit instance created.\")\n",
    "\n",
    "    agent_executor = create_sql_agent(\n",
    "        llm=llm,\n",
    "        toolkit=toolkit,\n",
    "        verbose=True,\n",
    "        agent_type=AgentType.OPENAI_FUNCTIONS\n",
    "    )\n",
    "    logging.info(\"SQL agent executor created.\")\n",
    "\n",
    "    agent_executor.run(\"what is the data is present in this database?\")\n",
    "    logging.info(\"Agent execution completed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error in setting up the environment: {str(e)}\")\n",
    "    slack_message += f\"Error in setting up the environment: {str(e)}\\n\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Slack API client\n",
    "SLACK_BOT_TOKEN =\"xoxb-6480955639828-6501691359936-LXNhmFOgwC2PRdfpwI6UU0kv\"\n",
    "SLACK_CHANNEL_ID = \"C06DVRG0962\"\n",
    "client = WebClient(token=SLACK_BOT_TOKEN)\n",
    "\n",
    "# Send Slack notification\n",
    "try:\n",
    "    if slack_message:\n",
    "        # If there are errors, send error message\n",
    "        message = f\"ETL Oracle job failed. Here's the summary of the errors:\\n{slack_message}\\n****Please check the logs for more details****\"\n",
    "    else:\n",
    "        # If successful, send success message\n",
    "        message = \"ETL Oracle job completed successfully\"\n",
    "\n",
    "    response = client.chat_postMessage(\n",
    "        channel=SLACK_CHANNEL_ID,\n",
    "        text=message\n",
    "    )\n",
    "    logging.info(\"Slack notification sent successfully.\")\n",
    "except SlackApiError as e:\n",
    "    logging.error(f\"Slack Notification Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import cx_Oracle\n",
    "import os\n",
    "import tiktoken\n",
    "import constantsp\n",
    "from langchain.chains import load_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from sqlalchemy import create_engine\n",
    "os.environ[\"OPENAI_API_KEY\"] = constantsp.APIKEY\n",
    "import openai\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import glob\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.agent_types import AgentType\n",
    "import logging\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "\n",
    "# Create a folder for logs\n",
    "logs_folder = 'etl_logs-sql'\n",
    "os.makedirs(logs_folder, exist_ok=True)\n",
    "\n",
    "# Configure the logging\n",
    "log_file_path = os.path.join(logs_folder, 'etl_sql.log')\n",
    "logging.basicConfig(filename=log_file_path, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', filemode='w')\n",
    "\n",
    "# Initialize Slack notification message\n",
    "slack_message = \"\"\n",
    "\n",
    "# Function to create SQLite database from CSV files\n",
    "def create_sqlite_db(csv_files, db_name):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_name)\n",
    "\n",
    "        for csv_file in csv_files:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            table_name = csv_file.split('.')[0]\n",
    "\n",
    "            df.to_sql(table_name, conn, index=False, if_exists='replace')\n",
    "            logging.info(f\"Table '{table_name}' created successfully from CSV file '{csv_file}'\")\n",
    "\n",
    "        # Close the database connection\n",
    "        conn.close()\n",
    "        logging.info(\"SQLite database connection closed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in creating SQLite database: {str(e)}\")\n",
    "        slack_message += f\"Error in creating SQLite database: {str(e)}\\n\"\n",
    "\n",
    "csv_files = glob.glob('output_sql_withslk/*.csv')\n",
    "db_name = 'sql.db'\n",
    "\n",
    "create_sqlite_db(csv_files, db_name)\n",
    "\n",
    "try:\n",
    "    db = SQLDatabase.from_uri(\"sqlite:///./sql.db\")\n",
    "    logging.info(\"SQLDatabase created successfully from SQLite database.\")\n",
    "\n",
    "    # Instantiate OpenAI\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "    logging.info(\"ChatOpenAI instance created.\")\n",
    "\n",
    "    toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "    logging.info(\"SQLDatabaseToolkit instance created.\")\n",
    "\n",
    "    agent_executor = create_sql_agent(\n",
    "        llm=llm,\n",
    "        toolkit=toolkit,\n",
    "        verbose=True,\n",
    "        agent_type=AgentType.OPENAI_FUNCTIONS\n",
    "    )\n",
    "    logging.info(\"SQL agent executor created.\")\n",
    "\n",
    "    agent_executor.run(\"what is the data is present in this database?\")\n",
    "    logging.info(\"Agent execution completed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error in setting up the environment: {str(e)}\")\n",
    "    slack_message += f\"Error in setting up the environment: {str(e)}\\n\"\n",
    "\n",
    "# Initialize Slack API client\n",
    "SLACK_BOT_TOKEN =\"xoxb-6480955639828-6501691359936-LXNhmFOgwC2PRdfpwI6UU0kv\"\n",
    "SLACK_CHANNEL_ID = \"C06DVRG0962\"\n",
    "client = WebClient(token=SLACK_BOT_TOKEN)\n",
    "\n",
    "# Send Slack notification\n",
    "try:\n",
    "    if slack_message:\n",
    "        # If there are errors, send error message\n",
    "        message = f\"ETL job failed. Here's the summary of the errors:\\n{slack_message}\\n****Please check the logs for more details****\"\n",
    "    else:\n",
    "        # If successful, send success message\n",
    "        message = \"ETL job SQL completed successfully\"\n",
    "\n",
    "    response = client.chat_postMessage(\n",
    "        channel=SLACK_CHANNEL_ID,\n",
    "        text=message\n",
    "    )\n",
    "    logging.info(\"Slack notification sent successfully.\")\n",
    "except SlackApiError as e:\n",
    "    logging.error(f\"Slack Notification Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import cx_Oracle\n",
    "import os\n",
    "from langchain.agents.agent_types import AgentType\n",
    "import constantsp\n",
    "from langchain.chains import load_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from sqlalchemy import create_engine\n",
    "os.environ[\"OPENAI_API_KEY\"] = constantsp.APIKEY\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = 'localhost'\n",
    "port = '1521'\n",
    "sid = 'xe'\n",
    "username = 'system'\n",
    "password = '12345'\n",
    "oracle_connection_string_fmt = (\n",
    "  'oracle+cx_oracle://{username}:{password}@' +\n",
    "  cx_Oracle.makedsn('{hostname}', '{port}', sid='{sid}')\n",
    ")\n",
    "url = oracle_connection_string_fmt.format(\n",
    "  username=username, password=password, \n",
    "  hostname=hostname, port=port, \n",
    "  sid=sid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(url, echo=True)\n",
    "db = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# llm_instance = OpenAI(temperature=0)\n",
    "db = db\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=0))\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "agent_executor.run(\"show table name EmployeeDemographics from this database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pyodbc\n",
    "from langchain_experimental.agents import create_csv_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "import constantsp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = constantsp.APIKEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = \"AdventureWorks2022\"\n",
    "server = \"OPTIMUS_PRIME\"\n",
    "db = SQLDatabase.from_uri(f\"mssql+pyodbc://{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\")\n",
    "# llm_instance = OpenAI(temperature=0)\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=0))\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"show mw data of the table present in this database?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import constantsp\n",
    "os.environ[\"OPENAI_API_KEY\"] = constantsp.APIKEY\n",
    "from langchain_experimental.agents.agent_toolkits import create_spark_dataframe_agent\n",
    "from langchain_openai import OpenAI\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "csv_file_path = \"DIMACCOUNT.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_spark_dataframe_agent(llm=OpenAI(temperature=0), df=df, verbose=True)\n",
    "\n",
    "agent.run(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('DIMACCOUNT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Pyspark_Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
